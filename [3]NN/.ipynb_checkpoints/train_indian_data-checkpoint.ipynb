{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization, LSTM, Embedding, Reshape\n",
    "from keras.models import load_model, model_from_json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "from os import mkdir, makedirs, remove, listdir\n",
    "\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./data/glove.6B.50d.txt','rb') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "glove_weights = np.zeros((len(lines), 50))\n",
    "words = []\n",
    "for i, line in enumerate(lines):\n",
    "    word_weights = line.split()\n",
    "    words.append(word_weights[0])\n",
    "    weight = word_weights[1:]\n",
    "    glove_weights[i] = np.array([float(w) for w in weight])\n",
    "word_vocab = [w.decode(\"utf-8\") for w in words]\n",
    "\n",
    "word2glove = dict(zip(word_vocab, glove_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.engine.topology import Layer\n",
    "import keras.backend as K\n",
    "from keras import initializers\n",
    "import numpy as np\n",
    "\n",
    "class Embedding2(Layer):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim, fixed_weights, embeddings_initializer='uniform', \n",
    "                 input_length=None, **kwargs):\n",
    "        kwargs['dtype'] = 'int32'\n",
    "        if 'input_shape' not in kwargs:\n",
    "            if input_length:\n",
    "                kwargs['input_shape'] = (input_length,)\n",
    "            else:\n",
    "                kwargs['input_shape'] = (None,)\n",
    "        super(Embedding2, self).__init__(**kwargs)\n",
    "    \n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.embeddings_initializer = embeddings_initializer\n",
    "        self.fixed_weights = fixed_weights\n",
    "        self.num_trainable = input_dim - len(fixed_weights)\n",
    "        self.input_length = input_length\n",
    "        \n",
    "        w_mean = fixed_weights.mean(axis=0)\n",
    "        w_std = fixed_weights.std(axis=0)\n",
    "        self.variable_weights = w_mean + w_std*np.random.randn(self.num_trainable, output_dim)\n",
    "\n",
    "    def build(self, input_shape, name='embeddings'):        \n",
    "        fixed_weight = K.variable(self.fixed_weights, name=name+'_fixed')\n",
    "        variable_weight = K.variable(self.variable_weights, name=name+'_var')\n",
    "        \n",
    "        self._trainable_weights.append(variable_weight)\n",
    "        self._non_trainable_weights.append(fixed_weight)\n",
    "        \n",
    "        self.embeddings = K.concatenate([fixed_weight, variable_weight], axis=0)\n",
    "        \n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if K.dtype(inputs) != 'int32':\n",
    "            inputs = K.cast(inputs, 'int32')\n",
    "        out = K.gather(self.embeddings, inputs)\n",
    "        return out\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if not self.input_length:\n",
    "            input_length = input_shape[1]\n",
    "        else:\n",
    "            input_length = self.input_length\n",
    "        return (input_shape[0], input_length, self.output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1287, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>more trouble for lalu prasad yadav case filed ...</td>\n",
       "      <td>a bjp elong leader has filed a case against rj...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>presidential elections sacked tmc elong mla s ...</td>\n",
       "      <td>six sacked mla s of trinamool congress tmc and...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subramanian swamy to meet yogi adityanath ram ...</td>\n",
       "      <td>senior bjp elong leader and rajya sabha mp elo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>keeping possibility of alliance in mind cong r...</td>\n",
       "      <td>while the congressu elong poll committee has d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>was attacked by tmc goons</td>\n",
       "      <td>state bjp elong national secretary rahul sinha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  more trouble for lalu prasad yadav case filed ...   \n",
       "1  presidential elections sacked tmc elong mla s ...   \n",
       "2  subramanian swamy to meet yogi adityanath ram ...   \n",
       "3  keeping possibility of alliance in mind cong r...   \n",
       "4                          was attacked by tmc goons   \n",
       "\n",
       "                                                text  label  \n",
       "0  a bjp elong leader has filed a case against rj...      0  \n",
       "1  six sacked mla s of trinamool congress tmc and...      0  \n",
       "2  senior bjp elong leader and rajya sabha mp elo...      0  \n",
       "3  while the congressu elong poll committee has d...      0  \n",
       "4  state bjp elong national secretary rahul sinha...      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/clean_indian_dataset.csv')\n",
    "df.columns = ['title','text','label']\n",
    "df.title = df.title.str.lower()\n",
    "df.text = df.text.str.lower()\n",
    "\n",
    "df.title = df.title.str.replace(r'http[\\w:/\\.]+','<URL>') # remove urls\n",
    "df.text = df.text.str.replace(r'http[\\w:/\\.]+','<URL>') # remove urls\n",
    "df.title = df.title.str.replace(r'[^\\.\\w\\s]','') #remove everything but characters and punctuation\n",
    "df.text = df.text.str.replace(r'[^\\.\\w\\s]','') #remove everything but characters and punctuation\n",
    "df.title = df.title.str.replace(r'\\.\\.+','.') #replace multple periods with a single one\n",
    "df.text = df.text.str.replace(r'\\.\\.+','.') #replace multple periods with a single one\n",
    "df.title = df.title.str.replace(r'\\.',' . ') #replace periods with a single one\n",
    "df.text = df.text.str.replace(r'\\.',' . ') #replace multple periods with a single one\n",
    "df.title = df.title.str.replace(r'\\s\\s+',' ') #replace multple white space with a single one\n",
    "df.text = df.text.str.replace(r'\\s\\s+',' ') #replace multple white space with a single one\n",
    "df.title = df.title.str.strip() \n",
    "df.text = df.text.str.strip() \n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Fraction of unique words in glove vectors: ', 0)\n",
      "('The number of unique words are: ', 28750)\n",
      "The first review looks like this: \n",
      "[7, 23, 19439, 63, 18, 651, 7, 160, 62, 501, 19439, 1300, 451, 19553, 12, 4019, 558, 1914, 1108, 168]\n",
      "And once this is converted back to words, it looks like: \n",
      "a bjp elong leader has filed a case against rjd elong supremo lalu prasadu s elder son tej pratap yadav\n"
     ]
    }
   ],
   "source": [
    "for li1 in range(len(df.text.values)):\n",
    "    if not type(df.text.values[li1]) is str:\n",
    "        print li1\n",
    "        \n",
    "\n",
    "\n",
    "all_text = ' '.join(df.text.values)\n",
    "words = all_text.split()\n",
    "u_words = Counter(words).most_common()\n",
    "u_words_counter = u_words\n",
    "u_words_frequent = [word[0] for word in u_words if word[1]>5] # we will only consider words that have been used more than 5 times\n",
    "\n",
    "u_words_total = [k for k,v in u_words_counter]\n",
    "word_vocab = dict(zip(word_vocab, range(len(word_vocab))))\n",
    "word_in_glove = np.array([w in word_vocab for w in u_words_total])\n",
    "\n",
    "words_in_glove = [w for w,is_true in zip(u_words_total,word_in_glove) if is_true]\n",
    "words_not_in_glove = [w for w,is_true in zip(u_words_total,word_in_glove) if not is_true]\n",
    "\n",
    "print('Fraction of unique words in glove vectors: ', sum(word_in_glove)/len(word_in_glove))\n",
    "\n",
    "word2num = dict(zip(words_in_glove,range(len(words_in_glove))))\n",
    "len_glove_words = len(word2num)\n",
    "freq_words_not_glove = [w for w in words_not_in_glove if w in u_words_frequent]\n",
    "b = dict(zip(freq_words_not_glove,range(len(word2num), len(word2num)+len (freq_words_not_glove))))\n",
    "word2num.update(b)\n",
    "\n",
    "word2num['<Other>'] = len(word2num)\n",
    "num2word = dict(zip(word2num.values(), word2num.keys()))\n",
    "\n",
    "int_text = [[word2num[word] if word in word2num else word2num['<Other>'] \n",
    "             for word in content.split()] for content in df.text.values]\n",
    "\n",
    "print('The number of unique words are: ', len(u_words))\n",
    "print('The first review looks like this: ')\n",
    "print(int_text[0][:20])\n",
    "print('And once this is converted back to words, it looks like: ')\n",
    "print(' '.join([num2word[i] for i in int_text[0][:20]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/H+ta4SolIVEuQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f24df7a1ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.hist([len(t) for t in int_text],50)\n",
    "#plt.show()\n",
    "\n",
    "plt.hist([len(t) for t in int_text],50)\n",
    "plt.xlabel(\"No. of words\")\n",
    "plt.ylabel(\"No. of articles\")\n",
    "plt.savefig(\"hist.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The number of articles greater than 500 in length is: ', 391)\n",
      "('The number of articles less than 500 in length is: ', 891)\n"
     ]
    }
   ],
   "source": [
    "print('The number of articles greater than 500 in length is: ', np.sum(np.array([len(t)>500 for t in int_text])))\n",
    "print('The number of articles less than 500 in length is: ', np.sum(np.array([len(t)<500 for t in int_text])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You cannot pass differing lengths of sentences to the algorithm. Hence we shall prepad the sentence with `<PAD>`. Sequences less than 500 in length will be prepadded and sequences that are longer than 500 will be truncated. It is assumed that the sentiment of the review can be asserted from the first 500 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num2word[len(word2num)] = '<PAD>'\n",
    "word2num['<PAD>'] = len(word2num)\n",
    "for i, t in enumerate(int_text):\n",
    "    if len(t)<500:\n",
    "        int_text[i] = [word2num['<PAD>']]*(500-len(t)) + t\n",
    "    elif len(t)>500:\n",
    "        int_text[i] = t[:500]\n",
    "    else:\n",
    "        continue\n",
    "x = np.array(int_text)\n",
    "y = df.as_matrix(columns=df.columns[[2]])\n",
    "\n",
    "# to get a 72,18,10 train-validate-test split, uncomment last line\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)\n",
    "#X_train,X_validate,y_train,y_validate = train_test_split(X_train,y_train,test_size = 0.2,random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding2_2 (Embedding2)    (None, None, 50)          997150    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,026,655\n",
      "Trainable params: 54,705\n",
      "Non-trainable params: 971,950\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding2(len(word2num), 50,\n",
    "                    fixed_weights=np.array([word2glove[w] for w in words_in_glove]))) # , batch_size=batch_size\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1158 samples, validate on 129 samples\n",
      "Epoch 1/15\n",
      "1158/1158 [==============================] - 14s 12ms/step - loss: 0.4394 - acc: 0.7608 - val_loss: 0.2906 - val_acc: 0.8527\n",
      "Epoch 2/15\n",
      "1158/1158 [==============================] - 13s 12ms/step - loss: 0.2909 - acc: 0.8670 - val_loss: 0.2390 - val_acc: 0.8682\n",
      "Epoch 3/15\n",
      "1158/1158 [==============================] - 17s 14ms/step - loss: 0.2412 - acc: 0.8929 - val_loss: 0.3425 - val_acc: 0.7984\n",
      "Epoch 4/15\n",
      "1158/1158 [==============================] - 14s 12ms/step - loss: 0.2275 - acc: 0.9016 - val_loss: 0.2079 - val_acc: 0.8992\n",
      "Epoch 5/15\n",
      "1158/1158 [==============================] - 13s 11ms/step - loss: 0.2076 - acc: 0.9154 - val_loss: 0.1602 - val_acc: 0.9302\n",
      "Epoch 6/15\n",
      "1158/1158 [==============================] - 13s 12ms/step - loss: 0.1823 - acc: 0.9240 - val_loss: 0.1302 - val_acc: 0.9457\n",
      "Epoch 7/15\n",
      "1158/1158 [==============================] - 14s 12ms/step - loss: 0.1490 - acc: 0.9413 - val_loss: 0.2021 - val_acc: 0.8760\n",
      "Epoch 8/15\n",
      "1158/1158 [==============================] - 13s 12ms/step - loss: 0.1621 - acc: 0.9361 - val_loss: 0.1326 - val_acc: 0.9612\n",
      "Epoch 9/15\n",
      "1158/1158 [==============================] - 13s 12ms/step - loss: 0.2020 - acc: 0.8990 - val_loss: 0.3014 - val_acc: 0.8217\n",
      "Epoch 10/15\n",
      "1158/1158 [==============================] - 13s 12ms/step - loss: 0.1863 - acc: 0.9154 - val_loss: 0.1807 - val_acc: 0.8992\n",
      "Epoch 11/15\n",
      "1158/1158 [==============================] - 13s 11ms/step - loss: 0.1634 - acc: 0.9318 - val_loss: 0.1041 - val_acc: 0.9535\n",
      "Epoch 12/15\n",
      "1158/1158 [==============================] - 13s 12ms/step - loss: 0.1165 - acc: 0.9594 - val_loss: 0.1623 - val_acc: 0.9302\n",
      "Epoch 13/15\n",
      "1158/1158 [==============================] - 13s 12ms/step - loss: 0.1012 - acc: 0.9611 - val_loss: 0.1437 - val_acc: 0.9302\n",
      "Epoch 14/15\n",
      "1158/1158 [==============================] - 13s 12ms/step - loss: 0.1194 - acc: 0.9499 - val_loss: 0.1565 - val_acc: 0.9535\n",
      "Epoch 15/15\n",
      "1158/1158 [==============================] - 13s 12ms/step - loss: 0.1212 - acc: 0.9542 - val_loss: 0.2034 - val_acc: 0.9457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4ed3501710>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#batch_size = 128\n",
    "batch_size = 64 # smaller for toy data\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=15, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.58774745]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"North korea is testing out missiles on americans living overseas .\".lower()\n",
    "sentence_num = [word2num[w] if w in word2num else word2num['<Other>'] for w in sentence.split()]\n",
    "sentence_num = [word2num['<PAD>']]*(500-len(sentence_num)) + sentence_num\n",
    "sentence_num = np.array(sentence_num)\n",
    "\n",
    "model.predict(sentence_num[None,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> north korea is testing out missiles on americans living overseas .'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([num2word[w] for w in sentence_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.21613051]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"President Trump is the greatest president of all time period .\".lower()\n",
    "sentence_num = [word2num[w] if w in word2num else word2num['<Other>'] for w in sentence.split()]\n",
    "sentence_num = [word2num['<PAD>']]*(0) + sentence_num\n",
    "sentence_num = np.array(sentence_num)\n",
    "model.predict(sentence_num[None,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 1s 5ms/step\n",
      "0.203447391705 0.945736434109\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model.evaluate(X_test, y_test)\n",
    "print loss,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0410177]] [0] correct\n",
      "[[ 0.15646861]] [0] correct\n",
      "[[ 0.41826612]] [1] wrong\n",
      "[[ 0.00027166]] [0] correct\n",
      "[[ 0.02912538]] [1] wrong\n",
      "[[ 0.00767875]] [1] wrong\n",
      "[[ 0.00034379]] [0] correct\n",
      "[[ 0.00115773]] [0] correct\n",
      "[[ 0.00120964]] [0] correct\n",
      "[[ 0.00024769]] [0] correct\n",
      "[[ 0.00026418]] [0] correct\n",
      "[[ 0.00024413]] [0] correct\n",
      "[[ 0.00023816]] [0] correct\n",
      "[[ 0.00024535]] [0] correct\n",
      "[[ 0.00026196]] [0] correct\n",
      "[[ 0.00445913]] [0] correct\n",
      "[[ 0.00560429]] [0] correct\n",
      "[[ 0.02822984]] [0] correct\n",
      "[[ 0.00030991]] [0] correct\n",
      "[[ 0.99562269]] [1] correct\n",
      "[[ 0.00025121]] [0] correct\n",
      "[[ 0.00869602]] [0] correct\n",
      "[[ 0.00024384]] [0] correct\n",
      "[[ 0.00023845]] [0] correct\n",
      "[[ 0.00831185]] [0] correct\n",
      "[[ 0.00026621]] [0] correct\n",
      "[[ 0.00107118]] [0] correct\n",
      "[[ 0.00502558]] [0] correct\n",
      "[[ 0.02392345]] [0] correct\n",
      "[[ 0.00024094]] [0] correct\n",
      "[[ 0.00023955]] [0] correct\n",
      "[[ 0.01981222]] [0] correct\n",
      "[[ 0.00024167]] [0] correct\n",
      "[[ 0.00037476]] [0] correct\n",
      "[[ 0.53399926]] [1] correct\n",
      "[[ 0.00972895]] [0] correct\n",
      "[[ 0.00025543]] [0] correct\n",
      "[[ 0.00658629]] [1] wrong\n",
      "[[ 0.9780513]] [1] correct\n",
      "[[ 0.00026173]] [0] correct\n",
      "[[ 0.0053375]] [0] correct\n",
      "[[ 0.94164336]] [1] correct\n",
      "[[ 0.02232246]] [1] wrong\n",
      "[[ 0.00025327]] [0] correct\n",
      "[[ 0.01043128]] [0] correct\n",
      "[[ 0.00603099]] [0] correct\n",
      "[[ 0.00857769]] [0] correct\n",
      "[[ 0.00025829]] [0] correct\n",
      "[[ 0.00026029]] [0] correct\n",
      "[[ 0.99572963]] [1] correct\n",
      "[[ 0.00818342]] [0] correct\n",
      "[[ 0.00022955]] [0] correct\n",
      "[[ 0.02647012]] [0] correct\n",
      "[[ 0.00024168]] [0] correct\n",
      "[[ 0.00025944]] [0] correct\n",
      "[[ 0.75540882]] [1] correct\n",
      "[[ 0.01740834]] [0] correct\n",
      "[[ 0.99573225]] [1] correct\n",
      "[[ 0.96821654]] [1] correct\n",
      "[[ 0.01278747]] [0] correct\n",
      "[[ 0.00024498]] [0] correct\n",
      "[[ 0.00023353]] [0] correct\n",
      "[[ 0.00024123]] [0] correct\n",
      "[[ 0.02161829]] [0] correct\n",
      "[[ 0.00353759]] [0] correct\n",
      "[[ 0.00608317]] [0] correct\n",
      "[[ 0.90493023]] [1] correct\n",
      "[[ 0.00101749]] [0] correct\n",
      "[[ 0.00025099]] [0] correct\n",
      "[[ 0.00027102]] [0] correct\n",
      "[[ 0.01729945]] [0] correct\n",
      "[[ 0.00632251]] [0] correct\n",
      "[[ 0.00027088]] [0] correct\n",
      "[[ 0.00024628]] [0] correct\n",
      "[[ 0.00030268]] [0] correct\n",
      "[[ 0.01229617]] [0] correct\n",
      "[[ 0.99555236]] [1] correct\n",
      "[[ 0.95100456]] [1] correct\n",
      "[[ 0.00023657]] [0] correct\n",
      "[[ 0.91256207]] [1] correct\n",
      "[[ 0.00023204]] [0] correct\n",
      "[[ 0.80678743]] [1] correct\n",
      "[[ 0.00742942]] [0] correct\n",
      "[[ 0.25588286]] [1] wrong\n",
      "[[ 0.02295933]] [0] correct\n",
      "[[ 0.00489254]] [0] correct\n",
      "[[ 0.00026123]] [0] correct\n",
      "[[ 0.00027395]] [0] correct\n",
      "[[ 0.01763708]] [0] correct\n",
      "[[ 0.91920221]] [1] correct\n",
      "[[ 0.00759008]] [0] correct\n",
      "[[ 0.0170048]] [0] correct\n",
      "[[ 0.00906682]] [0] correct\n",
      "[[ 0.01041497]] [0] correct\n",
      "[[ 0.83216131]] [1] correct\n",
      "[[ 0.01155583]] [0] correct\n",
      "[[ 0.00031841]] [0] correct\n",
      "[[ 0.99562919]] [1] correct\n",
      "[[ 0.01235604]] [0] correct\n",
      "[[ 0.00024675]] [0] correct\n",
      "[[ 0.99569005]] [1] correct\n",
      "[[ 0.93316519]] [1] correct\n",
      "[[ 0.00024835]] [0] correct\n",
      "[[ 0.88093966]] [1] correct\n",
      "[[ 0.00024292]] [0] correct\n",
      "[[ 0.00025009]] [0] correct\n",
      "[[ 0.00024741]] [0] correct\n",
      "[[ 0.00026458]] [0] correct\n",
      "[[ 0.00162273]] [0] correct\n",
      "[[ 0.0002572]] [0] correct\n",
      "[[ 0.0002526]] [0] correct\n",
      "[[ 0.00024576]] [0] correct\n",
      "[[ 0.00030473]] [0] correct\n",
      "[[ 0.00025389]] [0] correct\n",
      "[[ 0.0002499]] [0] correct\n",
      "[[ 0.87088299]] [1] correct\n",
      "[[ 0.02147968]] [0] correct\n",
      "[[ 0.0002413]] [0] correct\n",
      "[[ 0.99539524]] [1] correct\n",
      "[[ 0.00123619]] [0] correct\n",
      "[[ 0.01810621]] [0] correct\n",
      "[[ 0.00705291]] [0] correct\n",
      "[[ 0.00077732]] [0] correct\n",
      "[[ 0.0087551]] [0] correct\n",
      "[[ 0.01988924]] [1] wrong\n",
      "[[ 0.01145518]] [0] correct\n",
      "[[ 0.02047768]] [0] correct\n",
      "[[ 0.0186138]] [0] correct\n",
      "[[ 0.00984746]] [0] correct\n",
      "122\n",
      "101 21 7 0\n",
      "Accuracy =  0.945736434109\n",
      "Precision =  0.935185185185\n",
      "Recall =  1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "true_positive = 0\n",
    "true_negative = 0\n",
    "false_positive = 0\n",
    "false_negative = 0\n",
    "\n",
    "count = 0\n",
    "for li1 in range(len(X_test)):\n",
    "    prediction = model.predict(X_test[li1][None,:])\n",
    "    answer = y_test[li1]\n",
    "    print prediction,answer,\n",
    "    if (answer == 1 and prediction >= 0.5):\n",
    "        print \"correct\"\n",
    "        count += 1\n",
    "        true_negative = true_negative + 1\n",
    "        \n",
    "    elif (answer == 0 and prediction < 0.5):\n",
    "        print \"correct\"\n",
    "        count += 1\n",
    "        true_positive = true_positive + 1\n",
    "    else:\n",
    "        print \"wrong\"\n",
    "        if answer == 0:\n",
    "            false_negative = false_negative + 1\n",
    "        else:\n",
    "            false_positive = false_positive + 1\n",
    "\n",
    "print count    \n",
    "print true_positive,true_negative,false_positive,false_negative\n",
    "print \"Accuracy = \", float(count) / len(X_test)\n",
    "print \"Precision = \",float(true_positive) / (true_positive + false_positive)\n",
    "print \"Recall = \",float(true_positive) / (true_positive + false_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"indian_data_set_trained_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
